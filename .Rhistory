library(plyr)
download.data = function() {
"Checks for the Data directory and creates one if it doesn't exist"
if (!file.exists("Data")) {
message("Creating data directory")
dir.create("Data")
}
if (!file.exists("Data")) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2F
projectfiles%2FUCI%20HAR%20Dataset.zip"
zipfile="Data/UCI_HAR_data.zip"
message("Downloading data")
download.file(fileURL, destfile=zipfile, method="curl")
unzip(zipfile, exdir="Data")
}
}
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2F
projectfiles%2FUCI%20HAR%20Dataset.zip"
zipfile="Data/UCI_HAR_data.zip"
message("Downloading data")
download.file(fileURL, destfile=zipfile, method="curl")
unzip(zipfile, exdir="Data")
download.data = function() {
"Checks for the Data directory and creates one if it doesn't exist"
if (!file.exists("Data")) {
message("Creating data directory")
dir.create("Data")
}
if (!file.exists("Data")) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2F
projectfiles%2FUCI%20HAR%20Dataset.zip"
zipfile="Data/UCI_HAR_data.zip"
message("Downloading data")
download.file(fileURL, destfile=zipfile, method="curl")
unzip(zipfile, exdir="Data")
}
}
library(plyr)
wnload.data = function() {
"Checks for the Data directory and creates one if it doesn't exist"
if (!file.exists("Data")) {
message("Creating data directory")
dir.create("Data")
}
if (!file.exists("Data")) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2F
projectfiles%2FUCI%20HAR%20Dataset.zip"
zipfile="Data/UCI_HAR_data.zip"
message("Downloading data")
download.file(fileURL, destfile=zipfile, method="curl")
unzip(zipfile, exdir="Data")
}
}
download.data = function() {
"Checks for the Data directory and creates one if it doesn't exist"
if (!file.exists("Data")) {
message("Creating data directory")
dir.create("Data")
}
if (!file.exists("Data")) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
zipfile="Data/UCI_HAR_data.zip"
message("Downloading data")
download.file(fileURL, destfile=zipfile, method="curl")
unzip(zipfile, exdir="Data")
}
}
library("plyr", lib.loc="~/R/win-library/3.1")
download.data = function() {
"Checks for the Data directory and creates one if it doesn't exist"
if (!file.exists("Data")) {
message("Creating data directory")
dir.create("Data")
}
if (!file.exists("Data")) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
zipfile="Data/UCI_HAR_data.zip"
message("Downloading data")
download.file(fileURL, destfile=zipfile, method="curl")
unzip(zipfile, exdir="Data")
}
}
download.data
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
dir.create("Data")
library("httpRequest", lib.loc="~/R/win-library/3.1")
library("httpuv", lib.loc="~/R/win-library/3.1")
library("httr", lib.loc="~/R/win-library/3.1")
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
library(plyr)
download_data = function() {
"Checks for the Data directory and creates one if it doesn't exist"
if (!file.exists("Data")) {
dir.create("Data")
}
if (!file.exists("Data")) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
zipfile="Data/UCI_HAR_data.zip"
download.file(url=fileURL, destfile=zipfile, method="curl")
unzip(zipfile, exdir="Data")
}
}
library("reshape2", lib.loc="~/R/win-library/3.1")
detach("package:plyr", unload=TRUE)
library("plyr", lib.loc="~/R/win-library/3.1")
library(plyr)
library("plyr")
detach("package:plyr", unload=TRUE)
library("plyr")
library(plyr)
library(plyr)
library(reshape2)
dataPath <- "./data"
if (!file.exists(dataPath)) { dir.create(dataPath) }
fileName <- "Dataset.zip"
filePath <- paste(dataPath,fileName,sep="/")
if (!file.exists(filePath)) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url=fileURL,destfile=filePath,method="curl")
}
library(plyr)
library(reshape2)
# Create "Data" folder
dataPath <- "./Data"
if (!file.exists(dataPath)) { dir.create(dataPath) }
# Download Dataset zip file if the file does not exist
fileName <- "Dataset.zip"
filePath <- paste(dataPath,fileName,sep="/")
if (!file.exists(filePath)) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url=fileURL,destfile=filePath,method="curl")
}
fileName <- "Dataset.zip"
filePath <- paste(dataPath,fileName,sep="/")
if (!file.exists(filePath)) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
zipfile="Data/UCI_HAR_data.zip"
download.file(url=fileURL,destfile=filePath,method="curl")
}
dataPath <- "./Data"
if (!file.exists(dataPath)) { dir.create(dataPath) }
# Download Dataset zip file if the file does not exist
fileName <- "Dataset.zip"
filePath <- paste(dataPath,fileName,sep="/")
if (!file.exists(filePath)) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url=fileURL,destfile=filePath,method="curl")
}
library("rstudio", lib.loc="~/R/win-library/3.1")
library(plyr)
download.data = function() {
"Checks for data directory and creates one if it doesn't exist"
if (!file.exists("data")) {
message("Creating data directory")
dir.create("data")
}
if (!file.exists("data/UCI HAR Dataset")) {
# download the data
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
zipfile="data/UCI_HAR_data.zip"
message("Downloading data")
download.file(fileURL, destfile=zipfile, method="curl")
unzip(zipfile, exdir="data")
}
}
library(plyr)
download.data = function() {
"Checks for data directory and creates one if it doesn't exist"
if (!file.exists("data")) {
message("Creating data directory")
dir.create("data")
}
if (!file.exists("data/UCI HAR Dataset")) {
# download the data
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
zipfile="data/UCI_HAR_data.zip"
message("Downloading data")
download.file(fileURL, destfile=zipfile, method="curl")
unzip(zipfile, exdir="data")
}
}
install.packages("zipcode")
install.packages("zipfR")
dataPath <- "./Data"
if (!file.exists(dataPath)) { dir.create(dataPath) }
# Download Dataset zip file if the file does not exist
fileName <- "Dataset.zip"
filePath <- paste(dataPath,fileName,sep="/")
if (!file.exists(filePath)) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url=fileURL,destfile=filePath,method="curl")
}
dataPath <- "./Data"
if (!file.exists(dataPath)) { dir.create(dataPath) }
# Download Dataset zip file if the file does not exist
fileName <- "Dataset.zip"
filePath <- paste(dataPath,fileName,sep="/")
if (!file.exists(filePath)) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url=fileURL,destfile=filePath,method="curl")
}
library("data.table", lib.loc="~/R/win-library/3.1")
dataPath <- "./Data"
if (!file.exists(dataPath)) { dir.create(dataPath) }
# Download Dataset zip file if the file does not exist
fileName <- "Dataset.zip"
filePath <- paste(dataPath,fileName,sep="/")
if (!file.exists(filePath)) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url=fileURL,destfile=filePath,method="curl")
}
library(plyr)
library(reshape2)
# Create "Data" folder
dataPath <- "./Data"
if (!file.exists(dataPath)) { dir.create(dataPath) }
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",temp)
data <- read.table(unz(temp, "a1.dat"))
unlink(temp)
library(plyr)
library(reshape2)
# Create "Data" folder
dataPath <- "./Data"
if (!file.exists(dataPath)) { dir.create(dataPath) }
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",temp)
data <- read.table(unz(temp, "a1.dat"))
unlink(temp)
data <- read.table(unz(temp, "Dataset.dat"))
unlink(temp)
dataPath <- "./Data"
if (!file.exists(dataPath)) { dir.create(dataPath) }
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",temp)
data <- read.table(unz(temp, "Dataset.dat"))
unlink(temp)
data <- read.table(unz(temp, "UCI_HAR_data.zip"))
unlink(temp)
data <- read.table(unz(temp, "UCI_HAR_data.zip"))
unzip(zipfile, exdir="Data")
dataPath <- "./Data"
if (!file.exists(dataPath)) { dir.create(dataPath) }
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",temp)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2
FUCI%20HAR%20Dataset.zip",temp, mode="wb")
unzip(zipfile, exdir="Data")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",temp, mode="wb")
unzip(zipfile, exdir="Data")
unzip(zipfile, exdir="./Data")
unzip(zipfile, exdir="Data")
unzip(zipfile)
download.file
zipdata <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",temp, mode="wb")
unzip(zipfile=zipdata, exdir="./Data")
unzip(zipfile="zipdata", exdir="./Data")
zipdata <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",temp, mode="wb")
unzip(zipfile="zipdata", exdir="./Data")
zipdata
zipdata()
train_temp <- read.table("Data/train/X_train.txt")
test_temp <- read.table("Data/test/X_test.txt")
merge_x <- rbind(train_temp, test_temp)
train_temp <- read.table("Data/train/subject_train.txt")
test_temp <- read.table("Data/test/subject_test.txt")
merge_s <- rbind(train_temp, test_temp)
train_temp <- read.table("Data/train/y_train.txt")
test_temp <- read.table("Data/test/y_test.txt")
merge_y <- rbind(train_temp, test_temp)
features <- read.table("Data/features.txt")
extract_date <- grep("-mean\\(\\)|-std\\(\\)", features[, 2])
new_data <- merge_x[, extract_date]
names(new_data) <- features[extract_date, 2]
names(new_data) <- gsub("\\(|\\)", "", names(new_data))
names(new_data) <- tolower(names(new_data))
activities <- read.table("Data/activity_labels.txt")
activities[, 2] = gsub("_", "", tolower(as.character(activities[, 2])))
merge_y[,1] = activities[Y[,1], 2]
names(merge_y) <- "activity"
merge_y[,1] = activities[merge_y[,1], 2]
names(merge_y) <- "activity"
names(S) <- "subject"
cleaned <- cbind(merge_s, merge_y, merge_x)
write.table(cleaned, "Data/merged_clean_data.txt")
names(merge_s) <- "subject"
cleaned <- cbind(merge_s, merge_y, merge_x)
write.table(cleaned, "Data/merged_clean_data.txt")
unique_subject = unique(merge_s)[,1]
length_subject = length(unique(merge_s)[,1])
length_activities = length(activities[,1])
number_column = dim(cleaned)[2]
result = cleaned[1:(length_subject*length_activities), ]
row = 1
for (s in 1:length_subject) {
for (a in 1:length_activities) {
result[row, 1] = unique_subject[s]
result[row, 2] = activities[a, 2]
tmp <- cleaned[cleaned$subject==s & cleaned$activity==activities[a, 2], ]
result[row, 3:number_column] <- colMeans(tmp[, 3:number_column])
row = row+1
}
}
write.table(result, "data_set_with_the_averages.txt")
res2 <- read.table("data_set_with_the_averages.txt")
result[4,4]
res2[4,4]
res2[4,4]==result[4,4]
result[6,4]
res2[6,4]
res2[6,4]==result[6,4]
unique_subject = unique(merge_s)[,1]
length_subject = length(unique(merge_s)[,1])
length_activities = length(activities[,1])
number_column = dim(cleaned)[2]
new_data = cleaned[1:(length_subject*length_activities), ]
row = 1
for (s in 1:length_subject) {
for (a in 1:length_activities) {
new_data[row, 1] = unique_subject[s]
new_data[row, 2] = activities[a, 2]
tmp <- cleaned[cleaned$subject==s & cleaned$activity==activities[a, 2], ]
new_data[row, 3:number_column] <- colMeans(tmp[, 3:number_column])
row = row+1
}
}
write.table(new_data, "data_set_with_the_averages.txt")
res2 <- read.table("data_set_with_the_averages.txt")
new_data[4,4]
write.table(new_data, "data_set_with_the_averages.txt")
new_average <- read.table("data_set_with_the_averages.txt")
new_data[4,4]
new_average[4,4]
new_average[4,4]==new_data[4,4]
new_data[6,4]
new_average[6,4]
new_average[6,4]==new_data[6,4]
new_data
new_average
unique_subject = unique(merge_s)[,1]
length_subject = length(unique(merge_s)[,1])
length_activities = length(activities[,1])
number_column = dim(cleaned)[2]
new_data2 = cleaned[1:(length_subject*length_activities), ]
row = 1
for (s in 1:length_subject) {
for (a in 1:length_activities) {
new_data2[row, 1] = unique_subject[s]
new_data2[row, 2] = activities[a, 2]
tmp <- cleaned[cleaned$subject==s & cleaned$activity==activities[a, 2], ]
new_data2[row, 3:number_column] <- colMeans(tmp[, 3:number_column])
row = row+1
}
}
write.table(new_data2, "data_set_with_the_averages.txt")
new_average <- read.table("data_set_with_the_averages.txt")
new_data
new_data2
new_average
new_data
new_data2
new_average
new_data -
# This R script will merge two datasets into one, then prepare tidy data that
# can be used for further analysis.
# 1) Merges the training and the test sets to create one data set.
train_temp <- read.table("Data/train/X_train.txt")
test_temp <- read.table("Data/test/X_test.txt")
merge_x <- rbind(train_temp, test_temp)
train_temp <- read.table("Data/train/subject_train.txt")
test_temp <- read.table("Data/test/subject_test.txt")
merge_s <- rbind(train_temp, test_temp)
train_temp <- read.table("Data/train/y_train.txt")
test_temp <- read.table("Data/test/y_test.txt")
merge_y <- rbind(train_temp, test_temp)
# 2) Extracts only the measurements on the mean and standard deviation for each
# measurement.
features <- read.table("Data/features.txt")
extract_date <- grep("-mean\\(\\)|-std\\(\\)", features[, 2])
merge_x <- merge_x[, extract_data]
names(merge_x) <- features[extract_data, 2]
names(merge_x) <- gsub("\\(|\\)", "", names(merge_x))
names(merge_x) <- tolower(names(merge_x))
# 3) Uses descriptive activity names to name the activities in the data set.
activities <- read.table("Data/activity_labels.txt")
activities[, 2] = gsub("_", "", tolower(as.character(activities[, 2])))
merge_y[,1] = activities[merge_y[,1], 2]
names(merge_y) <- "activity"
# 4) Appropriately labels the data set with descriptive activity names.
names(merge_s) <- "subject"
cleaned <- cbind(merge_s, merge_y, merge_x)
write.table(cleaned, "Data/merged_clean_data.txt")
# 5) Creates a second, independent tidy data set with the average of each
# variable for each activity and each subject.
unique_subject = unique(merge_s)[,1]
length_subject = length(unique(merge_s)[,1])
length_activities = length(activities[,1])
number_column = dim(cleaned)[2]
new_data = cleaned[1:(length_subject*length_activities), ]
row = 1
for (s in 1:length_subject) {
for (a in 1:length_activities) {
new_data[row, 1] = unique_subject[s]
new_data[row, 2] = activities[a, 2]
tmp <- cleaned[cleaned$subject==s & cleaned$activity==activities[a, 2], ]
new_data[row, 3:number_column] <- colMeans(tmp[, 3:number_column])
row = row+1
}
}
write.table(new_data, "data_set_with_the_averages.txt")
new_average <- read.table("data_set_with_the_averages.txt")
# Dispalys the Final Variables
new_data
new_average
# This R script will merge two datasets into one, then prepare tidy data that
# can be used for further analysis.
# 1) Merges the training and the test sets to create one data set.
train_temp <- read.table("Data/train/X_train.txt")
test_temp <- read.table("Data/test/X_test.txt")
merge_x <- rbind(train_temp, test_temp)
train_temp <- read.table("Data/train/subject_train.txt")
test_temp <- read.table("Data/test/subject_test.txt")
merge_s <- rbind(train_temp, test_temp)
train_temp <- read.table("Data/train/y_train.txt")
test_temp <- read.table("Data/test/y_test.txt")
merge_y <- rbind(train_temp, test_temp)
# 2) Extracts only the measurements on the mean and standard deviation for each
# measurement.
features <- read.table("Data/features.txt")
extract_date <- grep("-mean\\(\\)|-std\\(\\)", features[, 2])
merge_x <- merge_x[, extract_data]
names(merge_x) <- features[extract_data, 2]
names(merge_x) <- gsub("\\(|\\)", "", names(merge_x))
names(merge_x) <- tolower(names(merge_x))
# 3) Uses descriptive activity names to name the activities in the data set.
activities <- read.table("Data/activity_labels.txt")
activities[, 2] = gsub("_", "", tolower(as.character(activities[, 2])))
merge_y[,1] = activities[merge_y[,1], 2]
names(merge_y) <- "activity"
# 4) Appropriately labels the data set with descriptive activity names.
names(merge_s) <- "subject"
cleaned <- cbind(merge_s, merge_y, merge_x)
write.table(cleaned, "Data/merged_clean_data.txt")
# 5) Creates a second, independent tidy data set with the average of each
# variable for each activity and each subject.
unique_subject = unique(merge_s)[,1]
length_subject = length(unique(merge_s)[,1])
length_activities = length(activities[,1])
number_column = dim(cleaned)[2]
new_data = cleaned[1:(length_subject*length_activities), ]
row = 1
for (s in 1:length_subject) {
for (a in 1:length_activities) {
new_data[row, 1] = unique_subject[s]
new_data[row, 2] = activities[a, 2]
tmp <- cleaned[cleaned$subject==s & cleaned$activity==activities[a, 2], ]
new_data[row, 3:number_column] <- colMeans(tmp[, 3:number_column])
row = row+1
}
}
write.table(new_data, "data_set_with_averages.txt")
new_average <- read.table("data_set_with_averages.txt")
# Dispalys the Final Variables
new_data
new_average
